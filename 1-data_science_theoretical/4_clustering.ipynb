{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QLoHHkVNapa-",
        "O2AOL0iLhAyM"
      ],
      "authorship_tag": "ABX9TyP+eRg3gTS4TMcHGDYhsyOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvtrip/ml_manifestations/blob/master/1-data_science_theoretical/4_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Understanding Clustering\n",
        "\n",
        "- Group a set of objects such that objets in the same group are more similar than to those in other groups.\n",
        "- Take a set of variables as input\n",
        "- Create clusters of records with homogeneous attribute values\n",
        "- Retail: cluster users based on spend behavior to plan promotions\n",
        "- streaming service: cluster users based on shows watched to generate recommendations\n",
        "- Pattern recognition: cluster metrics based on similarity of metric values\n",
        " - Insurance: cluster users with similar usage of isnurance to plan packages and premium\n",
        " - sports: cluster similar players for practice drills and team formations\n",
        " - Anomaly detection: cluster closely positioned data sets to mark the rest as anomalies\n",
        "\n",
        "\n",
        " **Properties**\n",
        " - All the data points in a cluster should be similar to eahc other\n",
        " - The data points from different clusters should be as different as possible"
      ],
      "metadata": {
        "id": "bOXGCs9kYwPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K means clustering"
      ],
      "metadata": {
        "id": "QLoHHkVNapa-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  choose a random number k\n",
        "2. select k random data points as centroids\n",
        "3. assign all the points to the closest cluster centroid\n",
        "4. recompute the centroid of newly formed clsuters\n",
        "5. Repeat steps 3 amd 4 until\n",
        "  - centroids of newly formed clsuters do not change\n",
        "  - points remain in the same cluster\n",
        "  - maximum number of interations are reached\n",
        "\n",
        "\n",
        "**Strength of k means clustering**  \n",
        "- Strength\n",
        "   - A simple interative algorithm that works quite well in practice\n",
        "   - Efficeint\n",
        "\n",
        "- Limitations   \n",
        "   - Selection of the value of k\n",
        "   - Sensisitve to noise and outliers\n",
        "   - runs into problems with clusters having non-globular shapes\n",
        "\n",
        "- Variations\n",
        "   - k-mediods: samne as k means but centroid is not an imaginary point, but one of points in the cluster\n",
        "   - k-centers: same as k-measn but goal is to maximize maximum diameter of the clusters   \n",
        "\n",
        "\n",
        "**HIERARCHICAL CLUSTERING**\n",
        "\n",
        "Steps\n",
        " - Start with the points as individual clusters\n",
        " - At each step, merge the closest pair of clusters until only one cluster left\n",
        " - visiualized with a dendogram\n",
        "\n",
        "\n",
        "-  **how to define similarity of clusetrs**\n",
        "      - minimum distance(btwn closest pts) is MINIMUM, loosely fomred clusters, conservative, when atleast some similarity is fine\n",
        "      - maximum distance(btwn farthest pts) is MINIMUM, tightly formed clusters, aggresive, when high similarity is need\n",
        "      - distance between centroids(safest in case of doubt)\n",
        "      - group average and so on\n",
        "\n",
        "1. Agglomerative\n",
        " - start with the points as individual clusters\n",
        " - At each step, merge the closest pair of clusters until only one cluster(or k clusters) left\n",
        "\n",
        "\n",
        "2. Divisive\n",
        " - start with one, all-inclusive cluster\n",
        " - At each step,slit a cluster until only each cluster contains a point(or there are k clusters)\n",
        "\n",
        "\n",
        "**Strength** \n",
        "\n",
        "- Produces a set of nested clusters organized as a hierarchical tree\n",
        "- can be visualized as a dendogram\n",
        "- Do not have to assume any fixwed number of clusters\n",
        "- Can get meningful taxonomies\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "- Sensitive to noise and outliers\n",
        "- Difficulty in handling clusters of different size and convex shapes"
      ],
      "metadata": {
        "id": "PkA78IZearx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Density based clustering"
      ],
      "metadata": {
        "id": "O2AOL0iLhAyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- key idea: partition points into dense regions separated by not-so-dense regions\n",
        "- how to measure density: density at a point p is the number of points within a circle of radius r\n",
        "- what is a dense region?: a circle of radius eps that contains at least m points\n",
        "\n",
        "\n",
        "**core point**\n",
        "- points that have more than m number of points within the radius r; These points belong in a dense region and are at the interior of a cluster\n",
        "\n",
        "**border point**\n",
        "- points that have fewer than m number of points within the radius r but are in the neighborhood of a core point\n",
        "\n",
        "**noise point**\n",
        "- points that are neither core nor border points\n",
        "\n",
        "\n",
        "**Density edge**\n",
        " - edge between 2 core points if they are within the distance Eps\n",
        "\n",
        "\n",
        "**Density connected points**\n",
        " - 2 points p and r are density-connected if there is a path of more density edges between p and r\n",
        "\n",
        "\n",
        "\n",
        "**STEPS**\n",
        "\n",
        "1. label points as core, border and noise\n",
        "2. Eliminate noise points\n",
        "3. For every core point p that has not been assigned to a cluster\n",
        "   - Create a new cluster with the point p and all the points that are density-connected to p\n",
        "4. Assign border points to the cluster of the closest core point\n",
        "\n",
        "\n",
        "**strength**\n",
        "- resistant to noise\n",
        "- can handle clusters of different shapes and sizes\n",
        "\n",
        "\n",
        "**limitations**\n",
        "- does not cluster all the points\n",
        "- struggles in scenarios of varying densitites\n",
        "- sensitive to parameters\n",
        "\n",
        "\n",
        "**Measuring effectivenes of clustering**\n",
        "\n",
        "-Dunn Index = min(inter cluster distance)/ max(intra cluster distnace)\n",
        "\n",
        "numerator ensures the clusters are far apart\n",
        "denominator ensures the clusters are compact\n",
        "\n",
        "\n",
        "-Silhouette Index = (Average inter cluster distance - average intra cluster distance)/ max(Average inter cluster distanc,average intra cluster distance)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4-YUES9PiJ9o"
      }
    }
  ]
}