{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4BYVYRAJiHq9YX6vd3/io"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "WIUYiYkHQTvZ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fjmLR2ynP9SR"
      },
      "outputs": [],
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "\n",
        "        self.feature = nn.Sequential(\n",
        "            # Define feature extractor here...\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(96, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(32 * 12 * 12, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, num)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.feature(x)\n",
        "\n",
        "        x = x.view(-1, 32*12*12)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_subset(full_train_set, full_test_set, label_one, label_two):\n",
        "\n",
        "    train_set = []\n",
        "    data_lim = 20000\n",
        "    for data in full_train_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                train_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    test_set = []\n",
        "    data_lim = 1000\n",
        "    for data in full_test_set:\n",
        "        if data_lim>0:\n",
        "            data_lim-=1\n",
        "            if data[1]==label_one or data[1]==label_two:\n",
        "                test_set.append(data)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return train_set, test_set"
      ],
      "metadata": {
        "id": "wjGKHTdgQRDC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model,optimizer,train_loader,epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "GTaClux2QNlZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model,test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        with torch.no_grad():\n",
        "            data, target = Variable(data), Variable(target)\n",
        "        output = model(data)\n",
        "        test_loss += F.cross_entropy(output, target, reduction='sum').item()#size_average=False\n",
        "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    acc=100. * float(correct.to(torch.device('cpu')).numpy())\n",
        "    test_accuracy = (acc / len(test_loader.dataset))\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "p8HaLLSCQLeE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data_one, input_data_two, epochs = 4, 9, 3\n",
        "\n",
        "label_one = int(input_data_one)\n",
        "label_two = int(input_data_two)\n",
        "epochs = int(epochs)\n",
        "\n",
        "if label_one!=label_two and 0<=label_one<=9 and 0<=label_two<=9:\n",
        "  torch.manual_seed(42)\n",
        "  # Load MNIST dataset\n",
        "  trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
        "  full_train_set = dset.MNIST(root='./data', train=True, transform=trans, download=True)\n",
        "  full_test_set = dset.MNIST(root='./data', train=False, transform=trans)\n",
        "  batch_size = 16\n",
        "  # Get final train and test sets\n",
        "  train_set, test_set = load_subset(full_train_set,full_test_set,label_one,label_two)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_set,batch_size=batch_size,shuffle=False)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset=test_set,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "  model = AlexNet()\n",
        "  if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "  optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "  for epoch in range(1, epochs+1):\n",
        "    train(model,optimizer,train_loader,epoch)\n",
        "    accuracy = test(model,test_loader)\n",
        "\n",
        "  print(round(accuracy,2))\n",
        "else:\n",
        "    print(\"Invalid input\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kb3173JIQKTj",
        "outputId": "8d14de2b-2011-4037-ec3b-2435c85ac70d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79.41\n"
          ]
        }
      ]
    }
  ]
}