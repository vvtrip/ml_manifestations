{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "F9Xw1j4ab54t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression is a technique to determine the relationship between two or more variables.\n",
        "\n",
        "You can apply regression to scenarios that require prediction or causal inference.\n",
        "\n",
        "You can use regression to understand the extent to which the area of a house affects the housing prices.\n",
        "\n",
        "Regress means predicting one variable from another.\n",
        "\n",
        "What can Regression Show ?\n",
        " - Regression can show how one variable varies with respect to another variable.\n",
        "\n",
        " - For example, the price of a wine bottle can vary depending on the average growing season temperature.\n",
        "\n",
        "What Regression cannot show ?\n",
        " - Regression cannot show any causal relationship between two variables.\n",
        "\n",
        " - For example, if the area of the house is an independent variable and the price of the house is a dependent variable, you cannot conclude that houses with larger areas will increase the price of the house.\n",
        "\n",
        "\n",
        " Correlation is a measure that describes the strength of relationship between two variables .\n",
        " \n",
        "Regression explains in more detail about this strength"
      ],
      "metadata": {
        "id": "gjcP_FCYb8CS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ERRORS**\n",
        "\n",
        "y - Dependent variable\n",
        "\n",
        "x - Independent variable\n",
        "\n",
        "e - Error measure\n",
        "\n",
        "B0 and B1 Parameters that best fit the model\n",
        "\n",
        "The actual values are scattered and the predicted values are along the line.\n",
        "\n",
        "The difference between actual and predicted values gives the error. This is also called the residual error (e).\n",
        "\n",
        "The parameters (Beta0 and Beta1) are chosen to minimize the total error between the actual and predicted values.\n",
        "\n",
        "You have seen how to fit a model that best describes the data. However, you can never get a perfect fit.\n",
        "\n",
        "**How will you measure the error/deviation in a model that is fit to the data ?**\n",
        "\n",
        "\n",
        "**SSE**\n",
        "\n",
        "Sum of Squared Errors (SSE) is a measure of the quality of the Regression Line .\n",
        "\n",
        "If there are n data points, then the SSE is the sum of square of the residual errors .\n",
        "\n",
        "SSE is small for the Line of Best Fit and big for the baseline model.\n",
        "\n",
        "The line with the minimum SSE is the Regression Line. SSE is sometimes difficult to interpret because,\n",
        "\n",
        "It depends on the number of values (n)\n",
        "\n",
        "The units are hard to comprehend\n",
        "\n",
        "So, is there a better way to gauge the quality of the Regression Model ?\n",
        "\n",
        "**RMSE**\n",
        "\n",
        "At times, the SSE is difficult to interpret and the units are difficult to comprehend. So, the alternative measure of quality is the Root Mean Square Error (RMSE).\n",
        "\n",
        "RMSE shrinks the magnitude of error by taking the square root of SSE divided by the number of observations (n).\n",
        "\n",
        "\n",
        "**Best Model Vs Baseline Model**\n",
        "\n",
        "\n",
        "The baseline model gives the Average value.\n",
        "\n",
        "The SSE values for baseline model is the Total Sum of Square values(SST)\n",
        "\n",
        "RSquare = 1 - ((SSE) / (SST))\n",
        "\n",
        "\n",
        "**R Square(R Sq) Properties**\n",
        "\n",
        "\n",
        "SSE and SST values should be greater than zero.\n",
        "\n",
        "R Sq lies between 0 and 1.\n",
        "\n",
        "R Sq is a unit less quantity.\n",
        "\n",
        "R Sq = 0 means the model is just as good as the base line and there is no improvement from the baseline model.\n",
        "\n",
        "R Sq = 1 means it is a perfect model. Ideally, you should strive towards getting the R Sq close to 1 . But some models with R Sq = 0 are also accepted depending on the scenario.\n",
        "\n",
        "\n",
        "**Model Interpretation**\n",
        "\n",
        "\n",
        "This is the equation for line of best fit\n",
        "\n",
        "y = 249.85714 - 0.7928571x\n",
        "\n",
        "For a unit change in X there is a .793 decrease in Y\n",
        "\n",
        "For a unit increase in price of the house, .793 lesser houses are sold .\n",
        "\n",
        "B0 is 249.85714\n",
        "\n",
        "B1 is -0.7928571"
      ],
      "metadata": {
        "id": "nsqHhOXpcWuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "kEzmehk7dYpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "price = [160,180,200,220,240,260,280]\n",
        "\n",
        "sale = [126,103,82,75,82,40,20]\n",
        "\n",
        "priceDF = pd.DataFrame(price, columns=list('x'))\n",
        "\n",
        "saleDF = pd.DataFrame(sale, columns=list('y'))\n",
        "\n",
        "houseDf = pd.concat((priceDF, saleDF),axis=1)\n",
        "\n",
        "print(houseDf)\n",
        "\n",
        "print(priceDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chrvxfVRdWyL",
        "outputId": "0cfa81f9-f2bb-4154-f7e8-4144470578ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     x    y\n",
            "0  160  126\n",
            "1  180  103\n",
            "2  200   82\n",
            "3  220   75\n",
            "4  240   82\n",
            "5  260   40\n",
            "6  280   20\n",
            "     x\n",
            "0  160\n",
            "1  180\n",
            "2  200\n",
            "3  220\n",
            "4  240\n",
            "5  260\n",
            "6  280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statsmodel can take input similar to R (Pass the variables with the dataframe) or take input as arrays.\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "smfModel = smf.ols('y~x',data=houseDf).fit()\n",
        "\n",
        "print(smfModel.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n_CA0M7da_s",
        "outputId": "b1f70e5c-3888-484a-8f11-754715d215be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.911\n",
            "Model:                            OLS   Adj. R-squared:                  0.893\n",
            "Method:                 Least Squares   F-statistic:                     50.93\n",
            "Date:                Sun, 30 Oct 2022   Prob (F-statistic):           0.000838\n",
            "Time:                        10:36:09   Log-Likelihood:                -26.006\n",
            "No. Observations:                   7   AIC:                             56.01\n",
            "Df Residuals:                       5   BIC:                             55.90\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept    249.8571     24.841     10.058      0.000     186.000     313.714\n",
            "x             -0.7929      0.111     -7.137      0.001      -1.078      -0.507\n",
            "==============================================================================\n",
            "Omnibus:                          nan   Durbin-Watson:                   1.995\n",
            "Prob(Omnibus):                    nan   Jarque-Bera (JB):                2.652\n",
            "Skew:                           1.442   Prob(JB):                        0.266\n",
            "Kurtosis:                       3.881   Cond. No.                     1.25e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.25e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n",
            "  \"samples were given.\" % int(n), ValueWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the Output**\n",
        "\n",
        "Dep. Variable: The Dependent Variable\n",
        "\n",
        "Model: Algorithm used. Here, it is Ordinary Least Squares\n",
        "\n",
        "Method: Parameter Fitting method. Here, it is Least Squares\n",
        "\n",
        "No. Observations: Number of rows used for model fitting.\n",
        "\n",
        "DF Residuals: The degrees of freedom of the residuals (Difference between the number of observations and parameters).\n",
        "\n",
        "DF Model: The degrees of freedom of the model (The number of parameters estimated in the model excluding the constant term) .\n",
        "\n",
        "R-squared: Measure that says how well the model has performed with respect to the baseline model."
      ],
      "metadata": {
        "id": "ufM1VJJYdtOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prep\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd \n",
        "boston = load_boston()\n",
        "california = fetch_california_housing()\n",
        "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "dataset['target'] = boston.target\n",
        "print(dataset.head()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdDxH5wUdnhZ",
        "outputId": "0a9aacf8-6857-4d15-a0fd-35e8fa983743"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
            "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
            "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
            "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
            "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
            "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
            "\n",
            "   PTRATIO       B  LSTAT  target  \n",
            "0     15.3  396.90   4.98    24.0  \n",
            "1     17.8  396.90   9.14    21.6  \n",
            "2     17.8  392.83   4.03    34.7  \n",
            "3     18.7  394.63   2.94    33.4  \n",
            "4     18.7  396.90   5.33    36.2  \n"
          ]
        }
      ]
    }
  ]
}