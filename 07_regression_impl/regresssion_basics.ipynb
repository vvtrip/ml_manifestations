{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSFv5rt5NmrHPhzDqqWqPG"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "F9Xw1j4ab54t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regression is a technique to determine the relationship between two or more variables.\n",
        "\n",
        "You can apply regression to scenarios that require prediction or causal inference.\n",
        "\n",
        "You can use regression to understand the extent to which the area of a house affects the housing prices.\n",
        "\n",
        "Regress means predicting one variable from another.\n",
        "\n",
        "What can Regression Show ?\n",
        " - Regression can show how one variable varies with respect to another variable.\n",
        "\n",
        " - For example, the price of a wine bottle can vary depending on the average growing season temperature.\n",
        "\n",
        "What Regression cannot show ?\n",
        " - Regression cannot show any causal relationship between two variables.\n",
        "\n",
        " - For example, if the area of the house is an independent variable and the price of the house is a dependent variable, you cannot conclude that houses with larger areas will increase the price of the house.\n",
        "\n",
        "\n",
        " Correlation is a measure that describes the strength of relationship between two variables .\n",
        " \n",
        "Regression explains in more detail about this strength"
      ],
      "metadata": {
        "id": "gjcP_FCYb8CS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ERRORS**\n",
        "\n",
        "y - Dependent variable\n",
        "\n",
        "x - Independent variable\n",
        "\n",
        "e - Error measure\n",
        "\n",
        "B0 and B1 Parameters that best fit the model\n",
        "\n",
        "The actual values are scattered and the predicted values are along the line.\n",
        "\n",
        "The difference between actual and predicted values gives the error. This is also called the residual error (e).\n",
        "\n",
        "The parameters (Beta0 and Beta1) are chosen to minimize the total error between the actual and predicted values.\n",
        "\n",
        "You have seen how to fit a model that best describes the data. However, you can never get a perfect fit.\n",
        "\n",
        "**How will you measure the error/deviation in a model that is fit to the data ?**\n",
        "\n",
        "\n",
        "**SSE**\n",
        "\n",
        "Sum of Squared Errors (SSE) is a measure of the quality of the Regression Line .\n",
        "\n",
        "If there are n data points, then the SSE is the sum of square of the residual errors .\n",
        "\n",
        "SSE is small for the Line of Best Fit and big for the baseline model.\n",
        "\n",
        "The line with the minimum SSE is the Regression Line. SSE is sometimes difficult to interpret because,\n",
        "\n",
        "It depends on the number of values (n)\n",
        "\n",
        "The units are hard to comprehend\n",
        "\n",
        "So, is there a better way to gauge the quality of the Regression Model ?\n",
        "\n",
        "**RMSE**\n",
        "\n",
        "At times, the SSE is difficult to interpret and the units are difficult to comprehend. So, the alternative measure of quality is the Root Mean Square Error (RMSE).\n",
        "\n",
        "RMSE shrinks the magnitude of error by taking the square root of SSE divided by the number of observations (n).\n",
        "\n",
        "\n",
        "**Best Model Vs Baseline Model**\n",
        "\n",
        "\n",
        "The baseline model gives the Average value.\n",
        "\n",
        "The SSE values for baseline model is the Total Sum of Square values(SST)\n",
        "\n",
        "RSquare = 1 - ((SSE) / (SST))\n",
        "\n",
        "\n",
        "**R Square(R Sq) Properties**\n",
        "\n",
        "\n",
        "SSE and SST values should be greater than zero.\n",
        "\n",
        "R Sq lies between 0 and 1.\n",
        "\n",
        "R Sq is a unit less quantity.\n",
        "\n",
        "R Sq = 0 means the model is just as good as the base line and there is no improvement from the baseline model.\n",
        "\n",
        "R Sq = 1 means it is a perfect model. Ideally, you should strive towards getting the R Sq close to 1 . But some models with R Sq = 0 are also accepted depending on the scenario.\n",
        "\n",
        "\n",
        "**Model Interpretation**\n",
        "\n",
        "\n",
        "This is the equation for line of best fit\n",
        "\n",
        "y = 249.85714 - 0.7928571x\n",
        "\n",
        "For a unit change in X there is a .793 decrease in Y\n",
        "\n",
        "For a unit increase in price of the house, .793 lesser houses are sold .\n",
        "\n",
        "B0 is 249.85714\n",
        "\n",
        "B1 is -0.7928571"
      ],
      "metadata": {
        "id": "nsqHhOXpcWuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression"
      ],
      "metadata": {
        "id": "kEzmehk7dYpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "price = [160,180,200,220,240,260,280]\n",
        "\n",
        "sale = [126,103,82,75,82,40,20]\n",
        "\n",
        "priceDF = pd.DataFrame(price, columns=list('x'))\n",
        "\n",
        "saleDF = pd.DataFrame(sale, columns=list('y'))\n",
        "\n",
        "houseDf = pd.concat((priceDF, saleDF),axis=1)\n",
        "\n",
        "print(houseDf)\n",
        "\n",
        "print(priceDF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chrvxfVRdWyL",
        "outputId": "7a8132a4-a64a-47f9-eb49-5c8d2e366f70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     x    y\n",
            "0  160  126\n",
            "1  180  103\n",
            "2  200   82\n",
            "3  220   75\n",
            "4  240   82\n",
            "5  260   40\n",
            "6  280   20\n",
            "     x\n",
            "0  160\n",
            "1  180\n",
            "2  200\n",
            "3  220\n",
            "4  240\n",
            "5  260\n",
            "6  280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statsmodel can take input similar to R (Pass the variables with the dataframe) or take input as arrays.\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "smfModel = smf.ols('y~x',data=houseDf).fit()\n",
        "\n",
        "print(smfModel.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n_CA0M7da_s",
        "outputId": "72113f78-73f8-4557-e863-23881948f18e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.911\n",
            "Model:                            OLS   Adj. R-squared:                  0.893\n",
            "Method:                 Least Squares   F-statistic:                     50.93\n",
            "Date:                Tue, 01 Nov 2022   Prob (F-statistic):           0.000838\n",
            "Time:                        01:08:45   Log-Likelihood:                -26.006\n",
            "No. Observations:                   7   AIC:                             56.01\n",
            "Df Residuals:                       5   BIC:                             55.90\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept    249.8571     24.841     10.058      0.000     186.000     313.714\n",
            "x             -0.7929      0.111     -7.137      0.001      -1.078      -0.507\n",
            "==============================================================================\n",
            "Omnibus:                          nan   Durbin-Watson:                   1.995\n",
            "Prob(Omnibus):                    nan   Jarque-Bera (JB):                2.652\n",
            "Skew:                           1.442   Prob(JB):                        0.266\n",
            "Kurtosis:                       3.881   Cond. No.                     1.25e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.25e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n",
            "  \"samples were given.\" % int(n), ValueWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding the Output**\n",
        "\n",
        "Dep. Variable: The Dependent Variable\n",
        "\n",
        "Model: Algorithm used. Here, it is Ordinary Least Squares\n",
        "\n",
        "Method: Parameter Fitting method. Here, it is Least Squares\n",
        "\n",
        "No. Observations: Number of rows used for model fitting.\n",
        "\n",
        "DF Residuals: The degrees of freedom of the residuals (Difference between the number of observations and parameters).\n",
        "\n",
        "DF Model: The degrees of freedom of the model (The number of parameters estimated in the model excluding the constant term) .\n",
        "\n",
        "R-squared: Measure that says how well the model has performed with respect to the baseline model."
      ],
      "metadata": {
        "id": "ufM1VJJYdtOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data prep\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.datasets import load_boston\n",
        "import pandas as pd \n",
        "boston = load_boston()\n",
        "california = fetch_california_housing()\n",
        "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "dataset['target'] = boston.target\n",
        "print(dataset.head()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdDxH5wUdnhZ",
        "outputId": "2bd8ca0b-d647-45bc-c2c0-92b72eba6718"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
            "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
            "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
            "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
            "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
            "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
            "\n",
            "   PTRATIO       B  LSTAT  target  \n",
            "0     15.3  396.90   4.98    24.0  \n",
            "1     17.8  396.90   9.14    21.6  \n",
            "2     17.8  392.83   4.03    34.7  \n",
            "3     18.7  394.63   2.94    33.4  \n",
            "4     18.7  396.90   5.33    36.2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression"
      ],
      "metadata": {
        "id": "4v_ur7Td7fDo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MLR model is represented as,\n",
        "\n",
        "y - Dependent variable\n",
        "\n",
        "x - Independent variable\n",
        "\n",
        "e - Error measure\n",
        "\n",
        "B0 , B1 ,B2 ... Bk Parameters that best fit the model\n",
        "\n",
        "**MLR**\n",
        "\n",
        "Multiple Regression helps in predicting a single variable using multiple independent variables. This improves the model by increasing the accuracy\n",
        "\n",
        "In today's complex world a given phenomenon(variable) is affected by more than one variable. Hence it is advised to opt for a Multiple Regression Model\n",
        "\n",
        "During this model fitting process, some variables will contribute significantly to the model but some might not. It is better to remove variables that are not of significance to the model. -So, how do we check if a variable is significant for the output?\n",
        "\n",
        "**Law of Diminishing Returns**\n",
        "\n",
        "More variables can increase the accuracy of the model. But sometimes the incremental value of adding each new variable might decrease.\n",
        "\n",
        "According to the Law of Diminishing Returns, the marginal improvement decreases as new variables are added.\n",
        "\n",
        "For example,\n",
        "\n",
        " - When you include x1 and x2 variables the R Sq = .8\n",
        " - When you add x3 to the model the R Sq might become .85 \n",
        " - Finally when you add x4 to this model the R Sq might become .87.\n",
        "In this process the incremental value has reduced from .05 to .02\n",
        "\n",
        "EXAMPLE\n",
        "\n",
        "Price(thousands of $) x\n",
        "\n",
        "Sales of new homes y\n",
        "\n",
        "Number of red cars z\n",
        "\n",
        "Data Source : http://www.yale.edu/statlab\n",
        "\n",
        "\n",
        "MLR Equation\n",
        "The MLR equation is, y = 252.85965 - .824935 x 1 + .3592748 x 2\n",
        "\n",
        "The number of houses sold is a linear function of both the price of a house and number of cars sold\n",
        "\n",
        "A unit increase in the number of cars sold increases the number of houses sold by a proportion of .35\n",
        "\n",
        "A unit increase in price of a house decreases the number of houses sold by a proportion of .82\n",
        "\n",
        "B0 252.85965\n",
        "\n",
        "B1 -0.824935\n",
        "\n",
        "B2 0.3592748\n",
        "\n",
        "\n",
        "**What is Multi Collinearity ?**\n",
        "\n",
        "Multi collinearity happens when two independent variables in a Multiple Regression model are correlated to each other. This will affect the outcome of your regression model.\n",
        "\n",
        "The best way to avoid multi collinearity is to omit one of the independent variables that is highly correlated with the other. The variable to omit depends on how the variable behaves in the presence of other variables.\n",
        "\n",
        "\n",
        "**Best Practices while Fitting MLR**\n",
        "\n",
        "Determine the correlation matrix of all the independent variables .\n",
        "\n",
        "Omit the terms that has high correlation with another.\n",
        "\n",
        "Remove the terms that do not predict the output significantly."
      ],
      "metadata": {
        "id": "MQbb6e8X7m7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Data Load\n",
        "# Let us consider the dataset available in the previous topic.\n",
        "# Price of the House , Number of units sold and the number of cars sold.\n",
        "# Let us create a dataframe from the list using the following code.\n",
        "\n",
        "import pandas as pd\n",
        "price = [160,180,200,220,240,260,280]\n",
        "sale = [126,103,82,75,82,40,20]\n",
        "cars = [0,9,19,5,25,1,20]\n",
        "priceDF = pd.DataFrame(price, columns=list('x'))\n",
        "saleDF = pd.DataFrame(sale, columns=list('y'))\n",
        "carsDf = pd.DataFrame(cars, columns=list('z'))\n",
        "houseDf = pd.concat([priceDF,saleDF,carsDf],axis=1)"
      ],
      "metadata": {
        "id": "qp2yll1D7jLr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fitting the Model\n",
        "# Here we fit the model by giving the dependent (number of units sold) and independent variables (price of the house, number of cars sold).\n",
        "\n",
        "X = houseDf.drop(['y'], axis=1)\n",
        "y = houseDf.y\n",
        "Xc = sm.add_constant(X)\n",
        "linear_regression = sm.OLS(y,Xc)\n",
        "fitted_model = linear_regression.fit()\n",
        "fitted_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "WrVpqNFO8T1U",
        "outputId": "3cfb6260-840c-4c55-a615-6027e7ab3d25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n",
            "  \"samples were given.\" % int(n), ValueWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.919\n",
              "Model:                            OLS   Adj. R-squared:                  0.879\n",
              "Method:                 Least Squares   F-statistic:                     22.74\n",
              "Date:                Tue, 01 Nov 2022   Prob (F-statistic):            0.00654\n",
              "Time:                        01:08:48   Log-Likelihood:                -25.654\n",
              "No. Observations:                   7   AIC:                             57.31\n",
              "Df Residuals:                       4   BIC:                             57.15\n",
              "Df Model:                           2                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        252.8597     26.812      9.431      0.001     178.417     327.302\n",
              "x             -0.8249      0.128     -6.445      0.003      -1.180      -0.470\n",
              "z              0.3593      0.552      0.650      0.551      -1.174       1.893\n",
              "==============================================================================\n",
              "Omnibus:                          nan   Durbin-Watson:                   1.646\n",
              "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.407\n",
              "Skew:                           0.546   Prob(JB):                        0.816\n",
              "Kurtosis:                       2.549   Cond. No.                     1.27e+03\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 1.27e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.919</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.879</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   22.74</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 01 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00654</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>01:08:48</td>     <th>  Log-Likelihood:    </th> <td> -25.654</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>     7</td>      <th>  AIC:               </th> <td>   57.31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>   57.15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  252.8597</td> <td>   26.812</td> <td>    9.431</td> <td> 0.001</td> <td>  178.417</td> <td>  327.302</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>     <td>   -0.8249</td> <td>    0.128</td> <td>   -6.445</td> <td> 0.003</td> <td>   -1.180</td> <td>   -0.470</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>z</th>     <td>    0.3593</td> <td>    0.552</td> <td>    0.650</td> <td> 0.551</td> <td>   -1.174</td> <td>    1.893</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   1.646</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.407</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.546</td> <th>  Prob(JB):          </th> <td>   0.816</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.549</td> <th>  Cond. No.          </th> <td>1.27e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.27e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting the Coef of the Model**\n",
        "\n",
        "The final equation is\n",
        "\n",
        "y = 126.45 - 0.55 * x - 0.322 * z\n",
        "\n",
        "the P(>|t|) values for each parameter is\n",
        "\n",
        "Constant Term 252.85965 is 0.001 - meaning - this term is significant in predicting the output\n",
        "\n",
        "x - House Price - -0.8249 is 0.003 - this term is also significant in predicting the output.\n",
        "\n",
        "z - car sales - 0.3593 is 0.551 this term is not so significant in predicting the output.\n",
        "\n",
        "We do not have to omit the third variable.\n",
        "\n",
        "\n",
        "\n",
        "**Interpreting the terms**\n",
        "\n",
        "Coef column gives the value of estimated coefficients (B0, B1, B2 etc.) .\n",
        "\n",
        "If the coef is zero then that independent variable does not predict the dependent variable correctly.\n",
        "\n",
        "Std err denotes how much each coefficient varies from the estimated value\n",
        "\n",
        "t-value - = Estimated coef/stderr\n",
        "\n",
        "P(>|t|) how likely the estimated value is zero\n",
        "\n",
        "- This value also indicates how significant a variable is to a model.\n",
        "- The smaller the value, the more significant a given variable is to the model.\n",
        "- it is better to remove variables with higher values of `P(>|t|)\n",
        "\n",
        "\n",
        "**MLR Model Building**\n",
        "\n",
        "- Consider that for a given dependent variable y, there are 4 independent variables x1,x2,x3 and x4 that affect the outcome. A possible way of building a Multiple Regression Model is to first use each independent variable separately against the dependent variable and measure the R-squared value.\n",
        "- Another way of doing this is by incrementally adding each independent variable and measuring the R-squared value for each combination.\n",
        "\n",
        "\n",
        "**Handling Multicollinearity**\n",
        "\n",
        "- A good practice while fitting multiple regression model is to check if there is any correlation among the independent variables.\n",
        "- In python, for a random array X the command to find correlation is X.corr().\n",
        "\n",
        "**Tips**\n",
        "\n",
        "Choose the coef with low Pr(>|t|) value.\n",
        "\n",
        "Reject that variable with correlation outside the range -0.7 and 0.7 with any other variable.\n",
        "\n"
      ],
      "metadata": {
        "id": "nHreYKSB8lTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us create a dataframe from the list using the following code.\n",
        "\n",
        "import pandas as pd\n",
        "price = [160,180,200,220,240,260,280]\n",
        "sale = [126,103,82,75,82,40,20]\n",
        "cars = [0,9,19,5,25,1,20]\n",
        "priceDF = pd.DataFrame(price, columns=list('x'))\n",
        "saleDF = pd.DataFrame(sale, columns=list('y'))\n",
        "carsDf = pd.DataFrame(cars, columns=list('z'))\n",
        "houseDf = pd.concat([priceDF,saleDF,carsDf],axis=1)"
      ],
      "metadata": {
        "id": "je1mEj7i9Etd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we fit the model by giving the dependent (number of units sold) and \n",
        "# independent variables (price of the house, number of cars sold).\n",
        "\n",
        "X = houseDf.drop(['y'], axis=1)\n",
        "y = houseDf.y\n",
        "Xc = sm.add_constant(X)\n",
        "linear_regression = sm.OLS(y,Xc)\n",
        "fitted_model = linear_regression.fit()\n",
        "fitted_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "gmDqAgFtuvHK",
        "outputId": "3ff127e6-bc62-439f-9bb3-981b7e324cda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  x = pd.concat(x[::order], 1)\n",
            "/usr/local/lib/python3.7/dist-packages/statsmodels/stats/stattools.py:75: ValueWarning: omni_normtest is not valid with less than 8 observations; 7 samples were given.\n",
            "  \"samples were given.\" % int(n), ValueWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   R-squared:                       0.919\n",
              "Model:                            OLS   Adj. R-squared:                  0.879\n",
              "Method:                 Least Squares   F-statistic:                     22.74\n",
              "Date:                Tue, 01 Nov 2022   Prob (F-statistic):            0.00654\n",
              "Time:                        01:08:48   Log-Likelihood:                -25.654\n",
              "No. Observations:                   7   AIC:                             57.31\n",
              "Df Residuals:                       4   BIC:                             57.15\n",
              "Df Model:                           2                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const        252.8597     26.812      9.431      0.001     178.417     327.302\n",
              "x             -0.8249      0.128     -6.445      0.003      -1.180      -0.470\n",
              "z              0.3593      0.552      0.650      0.551      -1.174       1.893\n",
              "==============================================================================\n",
              "Omnibus:                          nan   Durbin-Watson:                   1.646\n",
              "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.407\n",
              "Skew:                           0.546   Prob(JB):                        0.816\n",
              "Kurtosis:                       2.549   Cond. No.                     1.27e+03\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "[2] The condition number is large, 1.27e+03. This might indicate that there are\n",
              "strong multicollinearity or other numerical problems.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.919</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.879</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   22.74</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Tue, 01 Nov 2022</td> <th>  Prob (F-statistic):</th>  <td>0.00654</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>01:08:48</td>     <th>  Log-Likelihood:    </th> <td> -25.654</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td>     7</td>      <th>  AIC:               </th> <td>   57.31</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td>     4</td>      <th>  BIC:               </th> <td>   57.15</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>  252.8597</td> <td>   26.812</td> <td>    9.431</td> <td> 0.001</td> <td>  178.417</td> <td>  327.302</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>     <td>   -0.8249</td> <td>    0.128</td> <td>   -6.445</td> <td> 0.003</td> <td>   -1.180</td> <td>   -0.470</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>z</th>     <td>    0.3593</td> <td>    0.552</td> <td>    0.650</td> <td> 0.551</td> <td>   -1.174</td> <td>    1.893</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>   nan</td> <th>  Durbin-Watson:     </th> <td>   1.646</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th> <td>   nan</td> <th>  Jarque-Bera (JB):  </th> <td>   0.407</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>          <td> 0.546</td> <th>  Prob(JB):          </th> <td>   0.816</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>      <td> 2.549</td> <th>  Cond. No.          </th> <td>1.27e+03</td>\n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.27e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting the Coef of the Model**\n",
        "\n",
        "The final equation is\n",
        "\n",
        "y = 126.45 - 0.55 * x - 0.322 * z\n",
        "\n",
        "the P(>|t|) values for each parameter is\n",
        "\n",
        "Constant Term 252.85965 is 0.001 - meaning - this term is significant in predicting the output\n",
        "\n",
        "x - House Price - -0.8249 is 0.003 - this term is also significant in predicting the output.\n",
        "\n",
        "z - car sales - 0.3593 is 0.551 this term is not so significant in predicting the output.\n",
        "\n",
        "We do not have to omit the third variable."
      ],
      "metadata": {
        "id": "mGpQ3FsOvB91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpreting the terms**\n",
        "\n",
        "Coef column gives the value of estimated coefficients (B0, B1, B2 etc.) .\n",
        "\n",
        "If the coef is zero then that independent variable does not predict the dependent variable correctly.\n",
        "\n",
        "Std err denotes how much each coefficient varies from the estimated value\n",
        "\n",
        "t-value - = Estimated coef/stderr\n",
        "\n",
        "P(>|t|) how likely the estimated value is zero\n",
        "\n",
        "- This value also indicates how significant a variable is to a model.\n",
        "- The smaller the value, the more significant a given variable is to the model.\n",
        "- it is better to remove variables with higher values of `P(>|t|)`\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "6jUVSMwtvGjk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLR Model Building**\n",
        "\n",
        "- Consider that for a given dependent variable y, there are 4 independent variables x1,x2,x3 and x4 that affect the outcome. A possible way of building a Multiple Regression Model is to first use each independent variable separately against the dependent variable and measure the R-squared value.\n",
        "- Another way of doing this is by incrementally adding each independent variable and measuring the R-squared value for each combination."
      ],
      "metadata": {
        "id": "TdmG7oxAvKt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Multicollinearity**\n",
        "\n",
        "A good practice while fitting multiple regression model is to check if there is any correlation among the independent variables.\n",
        "In python, for a random array X the command to find correlation is X.corr()."
      ],
      "metadata": {
        "id": "NleRFAe5vQY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tips**\n",
        "\n",
        "Choose the coef with low Pr(>|t|) value.\n",
        "\n",
        "Reject that variable with correlation outside the range -0.7 and 0.7 with any other variable."
      ],
      "metadata": {
        "id": "SJX3RtPpvUxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Prep\n",
        "# Hope you've understood how to deal with multiple variables and perform multiple \n",
        "# regressions. Let us consider the dataset created using the following code for further practice.\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "california = fetch_california_housing()\n",
        "dataset = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
        "dataset['target'] = boston.target\n",
        "\n",
        "import statsmodels.api as sm\n",
        "dataset.iloc[:,:-1].corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rbKHxbHVu6uu",
        "outputId": "a67153fc-f615-451d-d781-8e9b8fcceaea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
              "CRIM     1.000000 -0.200469  0.406583 -0.055892  0.420972 -0.219247  0.352734   \n",
              "ZN      -0.200469  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
              "INDUS    0.406583 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
              "CHAS    -0.055892 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
              "NOX      0.420972 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
              "RM      -0.219247  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
              "AGE      0.352734 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
              "DIS     -0.379670  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
              "RAD      0.625505 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
              "TAX      0.582764 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
              "PTRATIO  0.289946 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
              "B       -0.385064  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
              "LSTAT    0.455621 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
              "\n",
              "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
              "CRIM    -0.379670  0.625505  0.582764  0.289946 -0.385064  0.455621  \n",
              "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
              "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
              "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
              "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
              "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
              "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
              "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
              "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
              "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
              "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
              "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
              "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2fc15089-d1da-42c0-8d4a-2679d645a194\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.200469</td>\n",
              "      <td>0.406583</td>\n",
              "      <td>-0.055892</td>\n",
              "      <td>0.420972</td>\n",
              "      <td>-0.219247</td>\n",
              "      <td>0.352734</td>\n",
              "      <td>-0.379670</td>\n",
              "      <td>0.625505</td>\n",
              "      <td>0.582764</td>\n",
              "      <td>0.289946</td>\n",
              "      <td>-0.385064</td>\n",
              "      <td>0.455621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>-0.200469</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.533828</td>\n",
              "      <td>-0.042697</td>\n",
              "      <td>-0.516604</td>\n",
              "      <td>0.311991</td>\n",
              "      <td>-0.569537</td>\n",
              "      <td>0.664408</td>\n",
              "      <td>-0.311948</td>\n",
              "      <td>-0.314563</td>\n",
              "      <td>-0.391679</td>\n",
              "      <td>0.175520</td>\n",
              "      <td>-0.412995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>0.406583</td>\n",
              "      <td>-0.533828</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062938</td>\n",
              "      <td>0.763651</td>\n",
              "      <td>-0.391676</td>\n",
              "      <td>0.644779</td>\n",
              "      <td>-0.708027</td>\n",
              "      <td>0.595129</td>\n",
              "      <td>0.720760</td>\n",
              "      <td>0.383248</td>\n",
              "      <td>-0.356977</td>\n",
              "      <td>0.603800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>-0.055892</td>\n",
              "      <td>-0.042697</td>\n",
              "      <td>0.062938</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.091203</td>\n",
              "      <td>0.091251</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>-0.099176</td>\n",
              "      <td>-0.007368</td>\n",
              "      <td>-0.035587</td>\n",
              "      <td>-0.121515</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>-0.053929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>0.420972</td>\n",
              "      <td>-0.516604</td>\n",
              "      <td>0.763651</td>\n",
              "      <td>0.091203</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.302188</td>\n",
              "      <td>0.731470</td>\n",
              "      <td>-0.769230</td>\n",
              "      <td>0.611441</td>\n",
              "      <td>0.668023</td>\n",
              "      <td>0.188933</td>\n",
              "      <td>-0.380051</td>\n",
              "      <td>0.590879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>-0.219247</td>\n",
              "      <td>0.311991</td>\n",
              "      <td>-0.391676</td>\n",
              "      <td>0.091251</td>\n",
              "      <td>-0.302188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.240265</td>\n",
              "      <td>0.205246</td>\n",
              "      <td>-0.209847</td>\n",
              "      <td>-0.292048</td>\n",
              "      <td>-0.355501</td>\n",
              "      <td>0.128069</td>\n",
              "      <td>-0.613808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>0.352734</td>\n",
              "      <td>-0.569537</td>\n",
              "      <td>0.644779</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>0.731470</td>\n",
              "      <td>-0.240265</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.747881</td>\n",
              "      <td>0.456022</td>\n",
              "      <td>0.506456</td>\n",
              "      <td>0.261515</td>\n",
              "      <td>-0.273534</td>\n",
              "      <td>0.602339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-0.379670</td>\n",
              "      <td>0.664408</td>\n",
              "      <td>-0.708027</td>\n",
              "      <td>-0.099176</td>\n",
              "      <td>-0.769230</td>\n",
              "      <td>0.205246</td>\n",
              "      <td>-0.747881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.494588</td>\n",
              "      <td>-0.534432</td>\n",
              "      <td>-0.232471</td>\n",
              "      <td>0.291512</td>\n",
              "      <td>-0.496996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.625505</td>\n",
              "      <td>-0.311948</td>\n",
              "      <td>0.595129</td>\n",
              "      <td>-0.007368</td>\n",
              "      <td>0.611441</td>\n",
              "      <td>-0.209847</td>\n",
              "      <td>0.456022</td>\n",
              "      <td>-0.494588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910228</td>\n",
              "      <td>0.464741</td>\n",
              "      <td>-0.444413</td>\n",
              "      <td>0.488676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>0.582764</td>\n",
              "      <td>-0.314563</td>\n",
              "      <td>0.720760</td>\n",
              "      <td>-0.035587</td>\n",
              "      <td>0.668023</td>\n",
              "      <td>-0.292048</td>\n",
              "      <td>0.506456</td>\n",
              "      <td>-0.534432</td>\n",
              "      <td>0.910228</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.460853</td>\n",
              "      <td>-0.441808</td>\n",
              "      <td>0.543993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>0.289946</td>\n",
              "      <td>-0.391679</td>\n",
              "      <td>0.383248</td>\n",
              "      <td>-0.121515</td>\n",
              "      <td>0.188933</td>\n",
              "      <td>-0.355501</td>\n",
              "      <td>0.261515</td>\n",
              "      <td>-0.232471</td>\n",
              "      <td>0.464741</td>\n",
              "      <td>0.460853</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.177383</td>\n",
              "      <td>0.374044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>-0.385064</td>\n",
              "      <td>0.175520</td>\n",
              "      <td>-0.356977</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>-0.380051</td>\n",
              "      <td>0.128069</td>\n",
              "      <td>-0.273534</td>\n",
              "      <td>0.291512</td>\n",
              "      <td>-0.444413</td>\n",
              "      <td>-0.441808</td>\n",
              "      <td>-0.177383</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.366087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>0.455621</td>\n",
              "      <td>-0.412995</td>\n",
              "      <td>0.603800</td>\n",
              "      <td>-0.053929</td>\n",
              "      <td>0.590879</td>\n",
              "      <td>-0.613808</td>\n",
              "      <td>0.602339</td>\n",
              "      <td>-0.496996</td>\n",
              "      <td>0.488676</td>\n",
              "      <td>0.543993</td>\n",
              "      <td>0.374044</td>\n",
              "      <td>-0.366087</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2fc15089-d1da-42c0-8d4a-2679d645a194')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2fc15089-d1da-42c0-8d4a-2679d645a194 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2fc15089-d1da-42c0-8d4a-2679d645a194');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fitted = sm.OLS(dataset.target, dataset.iloc[:,:-1]).fit()\n",
        "print(fitted.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0A9p3rU2oiG",
        "outputId": "e9e8dad0-ca14-479e-9689-28ecd194dc81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 OLS Regression Results                                \n",
            "=======================================================================================\n",
            "Dep. Variable:                 target   R-squared (uncentered):                   0.959\n",
            "Model:                            OLS   Adj. R-squared (uncentered):              0.958\n",
            "Method:                 Least Squares   F-statistic:                              891.3\n",
            "Date:                Tue, 01 Nov 2022   Prob (F-statistic):                        0.00\n",
            "Time:                        01:45:15   Log-Likelihood:                         -1523.8\n",
            "No. Observations:                 506   AIC:                                      3074.\n",
            "Df Residuals:                     493   BIC:                                      3128.\n",
            "Df Model:                          13                                                  \n",
            "Covariance Type:            nonrobust                                                  \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "CRIM          -0.0929      0.034     -2.699      0.007      -0.161      -0.025\n",
            "ZN             0.0487      0.014      3.382      0.001       0.020       0.077\n",
            "INDUS         -0.0041      0.064     -0.063      0.950      -0.131       0.123\n",
            "CHAS           2.8540      0.904      3.157      0.002       1.078       4.630\n",
            "NOX           -2.8684      3.359     -0.854      0.394      -9.468       3.731\n",
            "RM             5.9281      0.309     19.178      0.000       5.321       6.535\n",
            "AGE           -0.0073      0.014     -0.526      0.599      -0.034       0.020\n",
            "DIS           -0.9685      0.196     -4.951      0.000      -1.353      -0.584\n",
            "RAD            0.1712      0.067      2.564      0.011       0.040       0.302\n",
            "TAX           -0.0094      0.004     -2.395      0.017      -0.017      -0.002\n",
            "PTRATIO       -0.3922      0.110     -3.570      0.000      -0.608      -0.176\n",
            "B              0.0149      0.003      5.528      0.000       0.010       0.020\n",
            "LSTAT         -0.4163      0.051     -8.197      0.000      -0.516      -0.317\n",
            "==============================================================================\n",
            "Omnibus:                      204.082   Durbin-Watson:                   0.999\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1374.225\n",
            "Skew:                           1.609   Prob(JB):                    3.90e-299\n",
            "Kurtosis:                      10.404   Cond. No.                     8.50e+03\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
            "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[3] The condition number is large, 8.5e+03. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Improvement"
      ],
      "metadata": {
        "id": "EKcxyp9K37GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Occam's razor**\n",
        "\n",
        "- When you have two Multiple Regression Models fit for a given data set ,if one is simple and another is complex , choose the simple model.\n",
        "- Whenever you are in the Model Building exercise , start with a simple model and then build complexity on top of it.\n",
        "\n",
        "**TIP**\n",
        "\n",
        "Do not discard theoretical considerations based on statistical measures."
      ],
      "metadata": {
        "id": "PyQVTkCr4Dmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**\n",
        "\n",
        "- Your data-set might contain different features like independent variables (columns) with different magnitudes. So always bring them to a proper scale for ease of operation. This process is called feature scaling.\n",
        "- You can achieve Feature scaling with the help of either Normalization or Standardization depending on the magnitude of the variables."
      ],
      "metadata": {
        "id": "o0r0a0A04RMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "# Normalization is the process of re-scaling any value to the range [-1,1] .\n",
        "# Python has ready-made packages for re-scaling the data\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "sampleData = np.array([[ -3., -1.,  4.]])\n",
        "normalized_sampleData = preprocessing.normalize(sampleData)\n",
        "normalized_sampleData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnArcpxY3Thk",
        "outputId": "3400d90b-d42d-4011-d9cc-8048b3e34967"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.58834841, -0.19611614,  0.78446454]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardization\n",
        "# Standardization is the process of removing the arithmetic mean and dividing by the standard deviation.\n",
        "# Standardization in python is done in the following way:\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = np.array([[1,2,3,4,5]])\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "rescaledX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D8_tA9e4akV",
        "outputId": "1ac5956d-ee73-4ffe-a5da-45c5209e84e2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IsEtBc444k1u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}